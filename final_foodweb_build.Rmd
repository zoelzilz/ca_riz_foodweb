---
title: "final_foodweb"
output: html_document
date: "2024-04-23"
---

```{r packages, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

#install.packages("igraph") 
#install.packages("network") 
#install.packages("sna")
#install.packages("ggraph")
#install.packages("visNetwork")
#install.packages("threejs")
#install.packages("networkD3")
#install.packages("ndtv")
#install.packages("tidyverse")
#install.packages("NetIndices")
#install.packages("cheddar")

library(igraph) 
library(network) 
library(sna)
library(ggraph)
library(visNetwork)
library(threejs)
library(networkD3)
library(ndtv) 
library(tidyverse)
```

# Round One of Building: Generate Real Node List from Potential Node List Using Edge List
## First import both datasets
```{r import potential nodes and edge list}

## nodes ##
potential_nodes <- read_csv("data/RIZspecieslist_fulltaxonomy_2jun24.csv") %>% # updated to .1 version because I had to manually fix some higher taxonomy, then updated to 4/24 version because I fixed metadata of some dissection nodes, finally updated to 4/29 version because I had to add in an ass ton more links AND THEN AGAIN UPDATE TO 5/3 VERSION to fix some mistakes and finally 5/6 i hope; lol jk its june 2nd and i'm still updating things
  rename(nodeNum = id.x)
#View(potential_nodes)


## edges ##
edges_unclean <- read_csv("data/links_frommaster_7jun2024.csv") %>% # updated again jun 14 2024 to include some missing elements
  filter(!is.na(consumerNum)) %>% 
  filter(consumerNum != 0) %>% # removing consumers that I've already decided don't exist in the RIZ
  filter(!is.na(resourceNum)) %>% 
  filter(resourceNum != 0) %>%  # removing consumers that I've already decided don't exist in the RIZ
  
  # I didn't always fill in include code because the default should be to include it, but I do need to filter OUT some
  # unfortunately filtering also kicks out any NAs, so we need to replace those with 1s
  mutate(incl.code = case_when(is.na(incl.code) ~ 1,
                   .default = as.numeric(incl.code))) %>% 
  # now we can remove links that don't belong in the riz web:
  
  filter(incl.code != 7 # interaction occurs outside RIZ
         )
#View(edges_unclean)

```


## Then build real node list using edges and bind it with metadata from potential node list
```{r generate real node list from edges}

# first pull out dataframe of just consumers and their IDs
consumers_from_edgelist <- edges_unclean %>% 
  dplyr::select(consumerNum, consumerName) %>% 
  rename(nodeNum = consumerNum,
         nodeName = consumerName) # column names need to match resources df

# then dataframe of just resources and their IDs
resources_from_edgelist <- edges_unclean %>% 
  dplyr::select(resourceNum, resourceName) %>% 
  rename(nodeNum = resourceNum,
         nodeName = resourceName) # column names need to match consumers df

# stack them with rbind
all_nodes <- rbind(resources_from_edgelist, consumers_from_edgelist) %>% 
  #unique() # this would be the way to get unique ROWS but we only want to get unique nodeNUMS
  distinct(nodeNum, .keep_all = TRUE)
  
# got to this point in the code and realized that a lot of nodes in the edge list don't have id numbers even though they belong in the web, so leaving to manually fix those real quick
# fixed and updated edge list to version .1

# add attributes from potential nodes list
all_nodes_w_attributes <- left_join(all_nodes, potential_nodes, by = join_by(nodeNum)) %>% 
  dplyr::select(!nodeName) %>%  # removing this column because it's actually often innacurate (old sp name, etc)
  filter(!is.na(species))

### 1912 nodes, so about 400 in the list that didn't have any interactions. I can live with that # update, I could not live with that so I fixed them

```


## Now we should clean up our node list based on some of the attributes
### removing:
####- rare species
####- species whose commonality is listed as "not present" or "unclear"
####- anything that I coded as "web enter code" 0 
####- leaving "uncommon" and "unknown"

```{r cleaning up node list}

nodes_attributes_clean <- all_nodes_w_attributes %>% 
  
  # selecting nodes that are useful for end users
  dplyr::select(nodeNum, species, alternate_nomenclature, category, common_name, range,  body_size_mm, n_s_both, commonality, source, zone, habitat_notes, solitary_aggregating_colonial, mobile_or_sessile, trophic_strategy, notes, node_type, node_resolution, aphia, kingdom, phylum, class, order, family, genus, life_stage, web_enter_code) %>% 
  
  # changing column names so they're more useful to end users
  rename(synonymies = alternate_nomenclature,
         organismal_category = category, 
         province = n_s_both,
         reference_justification = source) %>% 
  
  # we're going to use life stages from this list instead of the ones I coded into the links (because I made mistakes), but we need to replace them with numbers:

  mutate(clean_stage = case_when(life_stage == "adult" ~ 1,
                                 life_stage == "medusa" ~ 1,
                                 life_stage == "big" ~ 1,
                                 species == "Peachia quinquecapitata"& life_stage == "juvenile" ~ 1,
                                 
                                 life_stage == "egg" ~ 2,
                                 life_stage == "eggs" ~2,
                                 
                                 # first stage larvae
                                 life_stage == "juvenile" & order == "Isopoda" ~ 3,
                                 life_stage == "juvenile" & order == "Amphipoda" ~ 3,
                                 life_stage == "larva" & organismal_category == "fish" ~ 3,
                                 life_stage == "larva" & organismal_category == "insect" ~ 3,
                                 life_stage == "larva" & organismal_category == "sea spider" ~ 3,
                                 life_stage == "larva" & organismal_category == "chiton" ~ 3, 
                                 life_stage == "larva" & organismal_category == "anemone" ~ 3, 
                                 life_stage == "procercoid" ~ 3,
                                 life_stage == "cysticercoid" ~ 3,
                                 life_stage == "cystacanth" ~ 3,
                                 life_stage == "hatchling" ~ 3,
                                 life_stage == "megalops" ~ 3,
                                 
                                 # second stage larvae
                                 life_stage == "plerocercoid" ~ 4,
                                 life_stage == "plerocercoid?" ~ 4,
                                 life_stage == "juvenile" & organismal_category == "fish" ~ 4, 
                                 life_stage == "juvenile" & str_detect(organismal_category, "snail") ~ 4, 
                                 life_stage == "juvenile" & organismal_category == "chiton" ~ 4, 
                                 life_stage == "juvenile" & organismal_category == "true crab" ~ 4, 
                                 life_stage == "juvenile" & organismal_category == "lobster" ~ 4, 
                                 life_stage == "juvenile" & organismal_category == "shark" ~ 4, 
                                 life_stage == "juvenile" & organismal_category == "brittle star" ~ 4, 
                                 life_stage == "juvenile" & organismal_category == "polychaete" ~ 4,
                                 life_stage == "juvenile" & organismal_category == "chaetognath" ~ 4,
                                 life_stage == "juvenile" & organismal_category == "acanthocephalan" ~ 4,
                                 life_stage == "juvenile" & organismal_category == "leech" ~ 4,
                                 life_stage == "pupae" ~ 4,
                                 life_stage == "small" ~ 4,
                                 life_stage == "young" ~ 4,
                                 str_detect(species, "nematode_") ~ 4, # all the nematodes I found in dissections were in crustaceans
                                 
                                 # 3rd stage larvae
                                 life_stage == "metacercaria" ~ 5,
                                 life_stage == "metacercariae" ~ 5,
                                 life_stage == "hydroid" ~ 5,
                                 life_stage == "hydroid colony" ~ 5,
                                 life_stage == "juvenile" & organismal_category == "barnacle" ~ 5,
                                 life_stage == "juvenile" & organismal_category == "copepod" ~ 5,
                                
                                 
                                 # these species are all L3 nematodes in fish
                                 str_detect(species, "Phocanema") ~ 5,
                                 species == "Anisakis sp." ~ 5,
                                 species == "Contracaecum sp." ~ 5,
                                 species == "Parafilaroides decorus" ~ 5,
                                 
                                 # multiple
                                 life_stage == "multiple" ~ 6,
                                 
                                 # dead
                                 is.na(life_stage) ~ 0, 
                                 
                                 .default = NA
                                   )) %>% 
  
  
# removing irrelevant species from node list
  filter(commonality != "rare",
         commonality != "very rare",
         commonality != "not present",
         commonality != "unclear") %>% 
# finally removing anything with web_enter_code = 0 (my last minute way of excluding nodes)
# unfortunately filtering also kicks out any NAs, so we need to replace those with 1s
  mutate(web_enter_code = case_when(is.na(web_enter_code) ~ 1,
                   .default = as.numeric(web_enter_code))) %>% 
  # now we can remove nodes that don't belong in the riz web:
  filter(web_enter_code != 0 # interaction occurs outside RIZ
         )

### down to 1680 reasonable nodes for the web

```

## Next step is to rebuild the edge list from our cleaned up node list, including relatively common species that are known to be present in the CA RIZ
#### we only want consumers/resources and their links in the web if those consumers/resources are in our clean node list

```{r rebuild edges from cleaned nodes}
# starting with 10,028 edges #

############# we will "filter" out unmatched consumers first #############

# create a list of just the nodes we are allowed to KEEP (numbers only) based on whats in clean node list
consumerNums_keep <- nodes_attributes_clean %>% 
  dplyr::select(nodeNum, species, organismal_category, clean_stage) %>% # we want all three of these because we will be replacing what's in the web with them
  rename(consumerNum = nodeNum,
         consumerName = species,
         consumerStage = clean_stage, 
         consumerCat = organismal_category) # to match consumerNum for joining

# inner join lets us make a dataset that keeps only the nodeNums (if we join by node num) that are in BOTH datasets

consumers_clean <- inner_join(consumerNums_keep, edges_unclean, by = join_by(consumerNum)) %>% 
  dplyr::select(!c(consumerName.y, consumerStage.y, consumerCat.y)) # keep the right versions of the node attributes

# down to 8822 edges, we filtered out a lot of rares/not presents I guess!

############# and finish by "filtering" out unmatched resources ############# 

# create a list of just the nodes we are allowed to KEEP (numbers only) - this dataset is identical to consumerNums_keep
resourceNums_keep <- nodes_attributes_clean %>% 
  dplyr::select(nodeNum, species, organismal_category, clean_stage) %>% 
  rename(resourceNum = nodeNum,
         resourceName = species,
         resourceStage = clean_stage,
         resourceCat = organismal_category) # to match consumerNum for joining

# inner join lets us make a dataset that keeps only the nodeNums (if we join by numbers) that are in BOTH datasets

edges_clean <- inner_join(resourceNums_keep, consumers_clean, by = join_by(resourceNum)) %>%  # we can name this one edges_clean because we're done!
  
  # we need to select out the edge list version of species name/life stage/category now:
  dplyr::select(!c(resourceName.y, resourceCat.y, resourceStage.y)) %>% 
  
  # and do some other housekeeping
  dplyr::select(!c(INITIALS, date_added)) %>% 
  rename(
         resourceName = resourceName.x,
         resourceStage = resourceStage.x,
         resourceCat = resourceCat.x,
         
         consumerName = consumerName.x,
         consumerStage = consumerStage.x,
         consumerCat = consumerCat.x
         )
```

## We also need to code in some missing elements of columns:
1. locality: if ref = 435, 436 (MAH, LS) then = "California" [done]
2. stage: if category = hydroid, = 5 [done]
3. confidence: if locality = california or CA and justification = 3, = 1. 
               if locality = california or CA and justification = 6, = 2.
               if locality /= california or CA and justification = 3, = 2. 
               if locality /= california or CA and justification = 6, = 3. 
               if anything else, 4 [done]
               
4. Justification: if incl "diss" = PO, if incl "PO", PO (done manually in excel)

```{r clean further by filling in gaps}

### pull in locations from new csv i just made of lit search locations
locs <- read_csv("data/litsearch_locations.csv") %>% 
  rename(ref_num = reference_number) %>% 
  select(ref_num, general_location_of_study) %>% 
  filter(!is.na(general_location_of_study)) %>% 
  distinct(ref_num, general_location_of_study) %>%  # keeps only one row for each reference : location combo
  mutate(general_location_of_study = str_remove_all(general_location_of_study, "\\.")) # remove periods

edges_locs <- left_join(edges_clean, locs, by = join_by(ref_num)) # creates a new dataframe where i pulled in locations of references and linked them to links using ref_num

######### pop in the missing elements (confidence, justification, locality) ##########

edges_cleaner <- edges_locs %>% 
  
  ###### LOCALITY ######
  # first unite the two locality cols into a new col
  unite("localities", c("localities", "general_location_of_study"), sep = "; ", na.rm = TRUE) %>% 

  mutate(localities = case_when(
    is.na(localities) & str_detect(ref_num, "435") ~ "California",
    is.na(localities) & str_detect(ref_num, "436") ~ "California",
    is.na(localities) & str_detect(ref_num, "205") ~ "Northeastern Pacific",
    .default = as.character(localities))
    ) %>% 
  
  ###### LIFESTAGE ######
  mutate(consumerStage = case_when(consumerCat == "hydroid" ~ "5", TRUE ~ as.character(consumerStage))) %>% # TRUE is same as default but apparently better
  mutate(resourceStage = case_when(resourceCat == "hydroid" ~ "5", TRUE ~ as.character(resourceStage))) %>% 
  
  ###### CONFIDENCE ######
  mutate(confidence = case_when(is.na(confidence) & str_detect(localities, ", CA|California") & justification == "3" ~ "1",
                                is.na(confidence) & str_detect(localities, ", CA|California") & justification == "6" ~ "2",
                                TRUE ~ as.character(confidence)
                                )) %>% 
  # if STILL NA then we're assuming not in ca
  mutate(confidence = case_when(is.na(confidence) & justification == "3" ~ "2",
                                is.na(confidence) & justification == "6" ~ "3",
                                is.na(confidence) & justification == "4" ~ "4",
                                is.na(confidence) & justification == "10" ~ "4",
                                is.na(confidence) & justification == "1" ~ "1",
                                is.na(confidence) & justification == "7" ~ "1",
                                is.na(confidence) & justification == "13" ~ "1",
                                TRUE ~ as.character(confidence)
                                )) %>% 
  # this is making a lot of duplicate rows for some reason so:
  distinct(resourceNum, resourceName, resourceCat, resourceStage, consumerNum, consumerName, consumerCat, consumerStage, interaction.type, ref_num, localities, .keep_all = TRUE) %>% 
  
  ## need to add one more line of code collapsing all localities for each reference
  group_by(resourceNum, resourceName, resourceCat, resourceStage, consumerNum, consumerName, consumerCat, consumerStage, interaction.type, ref_num) %>%
  summarize(localities = paste0(unique(localities), collapse = "; "))



# make a nice list with all of the confidences and references collapsed
edges_final <- edges_cleaner %>% 
  group_by(resourceNum, resourceName, resourceCat, resourceStage, consumerNum, consumerName, consumerCat, consumerStage, interaction.type) %>% 
  summarize(ref_num = paste0(ref_num, collapse = ", "),
            justification = min(justification), 
            #justification = paste0(justification, collapse = ", "), # actually, we want BEST justification, so using above instead
            localities = paste0(unique(localities), collapse = "; "), # collapse localities into one col, unique is important to remove duplicate locations
            confidence = min(confidence),
            incl.code = min(incl.code)
            ) # decided i dont need the other columns i left out


############# some dicking around ############# 

edges_experiment <- edges_clean %>% 
  group_by(resourceNum, consumerNum,interaction.type) %>% 
  summarize(ref_num = paste0(ref_num, collapse = ", "),
            justification = paste0(justification, collapse = ", "),
            confidence = min(confidence),
            incl.code = min(incl.code)
            )

view(edges_experiment)

what_missing <- anti_join(edges_final, edges_clean, by = join_by(consumerNum))
what_missing2 <- anti_join(edges_final, edges_clean, by = join_by(resourceNum))

# down to 8654 total edges... I'm guessing removing the "rare/not present" resources didn't cut as many because we really focused on nodes as consumers instead of nodes as diet items??
```


## We're going to take a pause to save these dataframes as CSVs for reproducibility's sake
```{r saving current working node list and edge list}

write_csv(nodes_attributes_clean, "data/foodweb_V4/nodes_final_3jun2024.csv")

write_csv(edges_final, "data/foodweb_V4/links_collapsed_3jun2024.csv")

write_csv(edges_clean, "data/foodweb_V4/links_final_3jun2024.csv")

```

## Really quick, let's check if we're going to run into any messes with trophic levels by making sure all of the primary consumers have feeding links (e.g. resources)
#### basically, we will cross check the consumer list with the resource list and make sure that the resources that AREN'T in the consumer list are all non-feeding organisms (primary producers, dead stuff, non feeding life stages)
```{r cross checking}

consumers <- edges_clean %>% 
  dplyr::select(consumerNum, consumerName, consumerStage, consumerCat) %>% 
  rename(num = consumerNum)

resources <- edges_clean %>% 
  dplyr::select(resourceNum, resourceName, resourceStage, resourceCat) %>% 
  rename(num = resourceNum)

resources_without_food <- anti_join(resources, consumers, by = join_by(num)) %>% # returns all rows in x without a match in y, so resources that don't have a match in consumers, right??
  # returned a lot of duplicates oops so
  unique()

#write_csv(resources_without_food, "data/nodes_needing_resources_29apr2024.csv")

# welp, there are too many to ignore so BACK TO THE DRAWING BOARD 4/24/2024
# as of 30 april, seems good, mostly eggs and algae
```


## Building the Web WITHOUT Parasites
### Now we are going to further parse the edges down to only include trophic links, and to exclude parasites (for now)
```{r trophic links only}

trophic_links1 <- edges_final %>% # swapping to "links" lingo because armand thinks it more intuitive, so fine
  ungroup() %>% 
  # need to remove non-trophic interactions!
  filter(interaction.type != 2, #epibiont
         interaction.type !=9, #endocommensal
         interaction.type !=10, #ectocommensal
         interaction.type !=22, #mutualism
         #interaction.type !=28, #boring # i think we need to leave boring in because of the gammarids that bore and eat
         interaction.type != 29) %>%  
  
  # and finally we need to add a column coding for parasitic interaction or nah
  mutate(parasitic = case_when(
    interaction.type > 4 & interaction.type < 8 ~ "y",
    interaction.type == 12 ~ "y",
    interaction.type > 23 & interaction.type < 27 ~ "y", # we're calling sessile micropredation parasitic here
    TRUE ~ "n"
  )) %>% 
    dplyr::select(resourceNum,consumerNum, interaction.type)  # RESOURCE NUM HAS TO GO FIRST OR WEB IS UPSIDEDOWN (resourcenum is FROM and consumernum is TO)
  

free_living_links <- trophic_links %>% 
  filter(parasitic == "n")

# check for duplicate nodes before creating igraph:
dupes <- nodes_attributes_clean%>% 
  group_by(nodeNum) %>% 
  filter(n()>1)

# none, excellent

```

### time to put together trophic links into two igraph objects, one with parasites and one without
```{r create igraph object}

######## w/ parasites first #########

trophic_web_psites1 <- graph_from_data_frame(d= trophic_links1, # all links
                             vertices = nodes_attributes_clean, # can use these nodes because igraph filters out nodes that don't have any interactions automatically
                             directed=T) # this makes sure resources (from) "point" to consumers (to)

trophic_web_psites <- delete_vertices(trophic_web_psites1, 
                                      which(igraph::degree(trophic_web_psites1) == 0)) # hoping this will remove all unlinked links

# we want to calculate degree to set the size of circles in the future:
deg_psites <- igraph::degree(trophic_web_psites, mode = "all") 
# put in later when we are editing graph vis

species_list <- unlist(V(trophic_web_psites)$species) #unlist makes this list of characters into a vector, we need this for checking shit

########## no parasites

#nodes_nopsites <- nodes_attributes_clean %>% 
#  filter(!str_detect(trophic_strategy, "parasit")) %>% 
#  filter(!trophic_strategy == "pathogen")

#trophic_web_nopsites <- graph_from_data_frame(d= free_living_links, # links
#                             vertices = nodes_nopsites, # nodes
#                             directed=T) # i think this makes sure consumers "point" to resources

# we want to calculate degree to set the size of circles in the future:
#deg <- igraph::degree(trophic_web_nopsites, mode = "all") 
# put in later when we are editing graph vis

```
### Now we can prep the web for visualization a little bit - using NetIndices package
#### We can also use netindices to calculate trophic level, which will help us better plot our network graph
```{r netIndices for trophic levels}
# following tutorial from 2013 :/ https://assemblingnetwork.wordpress.com/2013/07/01/network-basics-with-r-and-igraph-part-iii-of-iii/
library(NetIndices) # remember this masks select in dplyr

# we can use netindices to pull an adjacency matrix from our igraph web object

RIZadjmatrix <- as_adjacency_matrix(trophic_web_psites,
                                    sparse = FALSE) # necessary to get a regular matrix, which we need for....
 
# Get the basic network indices from the matrices with GenInd()
#RIZindices <- GenInd(RIZadjmatrix) # running this takes forever so its ## out

#RIZindices 
# TrophInd() takes in an adjacency matrix and gives an output of the trophic level of each node (TL)
# as well as an index of the degree of omnivory for each node (OI)
 
trophRIZ<-TrophInd(RIZadjmatrix)

trophic_level <- trophRIZ$TL # name this vector, we should be able to add it to the nodes
# takes a sec

# An interesting use for this trophic level function is to then use trophic level as a plotting parameter.
# This way, I can plot the food web nodes according to trophic height. I think that this adds greatly to a plot of a food web, since you can gain more information about the trophic structure of the web by simply glancing at the plot.
 
# First we need to create a two-column matrix identifying the x and y values for each node.
layout.matrix.1 <- matrix(nrow=length(V(trophic_web_psites)), # Rows equal to the number of vertices
                        ncol=2)
layout.matrix.1[,1] <- runif(length(V(trophic_web_psites))) # randomly assign positions along x-axis (like jitter)
layout.matrix.1[,2] <- trophRIZ$TL # y-axis value based on trophic level

 
# Now we can use these matrices to define the layout instead of using the circle layout
 
# par(mar=c(.1,.1,.1,.1),mfrow=c(1,2)) # wtf is this doing - parameterizing plot space maybe?
 
# test plot
rizvis <- plot.igraph(trophic_web_psites,
                      vertex.label = V(trophic_web_psites)$label, # this is terrible syntax, but it works
                      vertex.label.cex = .35,
                      vertex.size=3,
                      edge.arrow.size=.25#,
                     # layout=layout.matrix.1 # in the updated (june 2024) version of igraph this no longer works
                     )
 
# I am still working on the best way to plot the nodes along the x-axis. You may notice that using
# runif() means that there is some chance that two nodes with the same trophic level
# will be right on top of one another

########## repeat for NO parasite  web #########
#RIZadjmatrix_nopsites <- as_adjacency_matrix(trophic_web_nopsites,
#                                    sparse = FALSE) # necessary to get a regular matrix, which we need for....
 
#trophRIZ_nopsites<-TrophInd(RIZadjmatrix_nopsites)

#trophic_level_nopsites <- trophRIZ_nopsites$TL # name this vector, we should be able to add it to the nodes
# takes a sec

# First we need to create a two-column matrix identifying the x and y values for each node.
#layout.matrix.1.np <- matrix(nrow=length(V(trophic_web_nopsites)), # Rows equal to the number of vertices
#                        ncol=2)
#layout.matrix.1.np[,1] <- runif(length(V(trophic_web_nopsites))) # randomly assign positions along x-axis (like jitter)
#layout.matrix.1.np[,2] <- trophRIZ_psites$TL # y-axis value based on trophic level

```

### Let's Make it interactive so we can explore using visNetwork
```{r visNetwork}
library(visNetwork)
library(networkD3)

######### VISNETWORK #########

# need two data frames, vis.links and vis.nodes

# we will create them from elements of the igraph object, for the utmost consistency

# also - the node data frame needs to have an id column, and the link data needs to have from and to columns denoting the start and end of each tie.

vis.links <- igraph::as_data_frame(trophic_web_psites, what = "edges") # edges are links; this code has renamed the columns correctly for us, what luck!
  
vis.nodes <- igraph::as_data_frame(trophic_web_psites, what = "vertices")%>% # vertices are nodes
  rename(id = name) %>% 
  mutate(degree = deg_psites) %>%  # we calculated deg a while ago, now added it to df, it should match?!
  mutate(trophic = trophic_level) # should also match?? since it was created from the same list in the same order i fycjking hope


########## hide all below, old code #########
#vis.links <- trophic_links %>% 
#  rename(to = consumerNum) %>% 
#  rename(from = resourceNum) #right?

# now we need to make a node list that filters out anyone without a consumer, annoying (only do this for building the NetIndices web)
# another option for this is to remove nodes with degree = zero from the igraph object, but that returns a list that MIGHT not be in the same order as the original node list, which means the degree column we append on may not match up

# first pull out dataframe of just consumers and their IDs
#t_consumers <- trophic_links %>% 
#  dplyr::select(consumerNum) %>% 
#  rename(nodeNum = consumerNum) # column names need to match resources df
# then dataframe of just resources and their IDs
#t_resources <- trophic_links %>% 
#  dplyr::select(resourceNum) %>% 
#  rename(nodeNum = resourceNum) # column names need to match consumers df
# stack them with rbind
#trophic_nodes_only <- rbind(t_consumers, t_resources) %>% 
#  distinct(nodeNum, .keep_all = TRUE)
# add attributes from potential nodes list
#trophic_nodes <- left_join(trophic_nodes_only, nodes_attributes_clean, by = join_by(nodeNum))

#vis.nodes <- trophic_nodes %>% 
#  rename(id = nodeNum) %>% 
#  mutate(degree = deg_psites) %>%  # we calculated deg a while ago, now added it to df, let's hope it matches
#  mutate(trophic = trophic_level)


######## now lets get fancy!! copied from tutorial ##########

vis.nodes$shape  <- "dot"  
vis.nodes$shadow <- TRUE # Nodes will drop shadow
vis.nodes$title  <- vis.nodes$species # Text on click is species name
vis.nodes$label  <- vis.nodes$trophic # Node label # shows up all the time, we don't want that
vis.nodes$size   <- 10 #vis.nodes$degree # use degree to determine node size
vis.nodes$borderWidth <- 1 # Node border width
vis.nodes$y <- layout.matrix.1[,2] # trying this out instead of layout.norm
vis.nodes$x <- layout.matrix.1[,1]

# mutate in a column for color
vis.nodes <- vis.nodes %>% 
  mutate(color = case_when(trophic_strategy == "grazer" ~ "darkgreen",
                           trophic_strategy == "micropredator" ~ "pink",
                           trophic_strategy ==   "non-feeding" ~ "grey",
                           trophic_strategy ==     "various (assemblage)" ~ "grey",
                           trophic_strategy ==     "detritivore" ~ "tan",
                           trophic_strategy ==     "scavenger" ~ "tan",
                           trophic_strategy ==     "deposit feeder" ~ "tan",
                           trophic_strategy ==   "filter feeder" ~ "blue",
                           trophic_strategy ==     "primary producer" ~ "limegreen",
                           trophic_strategy ==     "mixotroph" ~ "limegreen",
                           trophic_strategy ==     "omnivore" ~ "orange",
                           trophic_strategy ==     "typical predator" ~ "purple",
                           trophic_strategy ==     "carnivore (scavenger + predator)" ~ "purple",
                           trophic_strategy ==     "parasite" ~ "red",
                           trophic_strategy ==     "ectoparasite" ~ "red",
                           trophic_strategy ==     "pathogen" ~ "red",
                           trophic_strategy ==    "parasitic castrator" ~ "red",
                           .default = "black"))

visNetwork(vis.nodes, vis.links, width = "2000px", height = "2000px"
           ) %>% 
  visPhysics(enabled = FALSE) %>% 
  visIgraphLayout(layout = "layout.norm", layoutMatrix = layout.matrix.1) %>%   # woo this one worked! but it's upsidedown
  visOptions(selectedBy =  "trophic_strategy",
             highlightNearest = list(enabled = T, 
                                     #degree = c(from = 1, to = 1) # this should work but throws a JSON related error, i think becayse layout isn't hierarchical?
                                     algorithm = "hierarchical",
                                     degree = list(from = 1, to = 1) # i cannot get these to work correctly
                                     ) 
             )

```

```{r troubleshooting}

############ there are still a lot of consumers at the "bottom" ############

resources <- trophic_links2 %>% 
  dplyr::select(from) %>% 
  rename(nodeNum = from) 

consumers <- trophic_links2 %>% 
  dplyr::select(to) %>% 
  rename(nodeNum = to)

resources_without_food <- anti_join(resources, consumers, by = join_by(nodeNum)) %>% # returns all rows in x without a match in y, so resources that don't have a match in consumers, right??
  # returned a lot of duplicates oops so
  unique() %>% 
  left_join(., nodes_attributes_clean, by = join_by(nodeNum))
```


```{r test delete later}

x <- data.frame(num = c(1,2,3,5,6,7,10),
                name.x = c("a","b","c","d","e","f","g"))

y <- data.frame( num = c(1,2,3,4,5,6,7,8,9,10),
                 name.y = c("a","b","c","d","e","f","g", "h", "i", "j"))

z <- anti_join(x, y) # should return the rows in x that don't have a match in y, which should be none
z

a <- anti_join(y, x) # should return the rows in y that don't have a match in x, which should be 4, 8, 9
a

```


### Found a new package called metanetwork, let's play with that
```{r}
install.packages("metanetwork")
library(metanetwork)
```


### Finally we can make nice figures
Here's the new figure with different colored nodes and links based on interaction type
```{r pretty network graphs}

# fuck igraph, the syntax is poop. let's try with ggplot
library(ggraph)

######## full web first ########

trophic_layout <- create_layout(trophic_web_psites, #igraph object
                                layout = layout.matrix.1) # we constructed this layout.matrix.1 earlier by hand kinda using trophic levels
# later we use trophic_layout in place of "trophic_web" as the graph object

web_full <- ggraph(trophic_layout) + 
  geom_edge_link(aes(edge_color = interaction.type)) +
  #scale_edge_color_manual(values = c(3 = "green",
  #                                   1 = "red",
  #                                   30 = "grey"))+

  geom_node_point(aes(size = deg_psites, # size of nodes based on number of links
                      color = trophic_strategy
                      ))+
  
  #scale_color_manual(values = c("grazer" = "darkgreen",
   #                             "micropredator" = "pink",
   #                            "non-feeding" = "grey",
   #                             "various (assemblage)" = "grey",
   #                             "detritivore" = "tan",
   #                             "scavenger" = "tan",
   #                             "deposit feeder" = "tan",
    #                            "filter feeder" = "blue",
  #                              "primary producer" = "limegreen",
  #                              "mixotroph" = "limegreen",
  #                              "omnivore" = "orange",
  #                              "typical predator" = "purple",
  #                              "carnivore (scavenger + predator)" = "purple",
  #                              "parasite" = "red",
  #                              "ectoparasite" = "red",
  #                              "pathogen" = "red",
   #                             "parasitic castrator" = "red"))+
  geom_node_text(aes(label = species), size=3, color="gray50", repel=T)+
  theme_void()

```

### Actually calculating indices using cheddar